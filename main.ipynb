{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d8b10-65d6-4b72-b1e2-0bb5e9eba8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import chardet\n",
    "\n",
    "class CSVToParquetConverter:\n",
    "    def __init__(self, csv_file, parquet_file, chunksize=100_000):\n",
    "        self.csv_file = csv_file\n",
    "        self.parquet_file = parquet_file\n",
    "        self.chunksize = chunksize\n",
    "        self.codificacao = self.detectar_codificacao()\n",
    "        self.parquet_writer = None\n",
    "\n",
    "    def detectar_codificacao(self):\n",
    "        with open(self.csv_file, 'rb') as f:\n",
    "            resultado = chardet.detect(f.read(100000))\n",
    "        print(f\"Codificação detectada: {resultado['encoding']}\")\n",
    "        return resultado['encoding']\n",
    "\n",
    "    def converter(self):\n",
    "        try:\n",
    "            csv_stream = pd.read_csv(\n",
    "                self.csv_file, sep=';', chunksize=self.chunksize, low_memory=False, encoding=self.codificacao, on_bad_lines='skip'\n",
    "            )\n",
    "\n",
    "            for i, chunk in enumerate(csv_stream):\n",
    "                print(f\"Processando chunk {i}\")\n",
    "                if i == 0:\n",
    "                    self.inicializar_parquet_writer(chunk)\n",
    "                \n",
    "                self.escrever_chunk(chunk)\n",
    "\n",
    "            self.finalizar()\n",
    "\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Erro ao decodificar o arquivo: {e}\")\n",
    "\n",
    "    def inicializar_parquet_writer(self, chunk):\n",
    "        parquet_schema = pa.Table.from_pandas(df=chunk).schema\n",
    "        self.parquet_writer = pq.ParquetWriter(self.parquet_file, parquet_schema, compression='gzip')\n",
    "\n",
    "    def escrever_chunk(self, chunk):\n",
    "        table = pa.Table.from_pandas(chunk, schema=self.parquet_writer.schema)\n",
    "        self.parquet_writer.write_table(table)\n",
    "\n",
    "    def finalizar(self):\n",
    "        if self.parquet_writer:\n",
    "            self.parquet_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8c670-3a07-432a-a57e-932767b2c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso:\n",
    "file_name = 'nome_do_arquivo'\n",
    "csv_file = f'./files/csv/{file_name}.csv'\n",
    "parquet_file = f'./files/parquet/{file_name}.parquet'\n",
    "\n",
    "converter = CSVToParquetConverter(csv_file, parquet_file)\n",
    "converter.converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305058fa-8571-480f-a209-4b55438729c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Exemplo de uso:\n",
    "parquet_file = f'./files/parquet/{file_name}.parquet'\n",
    "df = pd.read_parquet(parquet_file)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8cdb1-f3c0-4074-9175-52d1b6cf0375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
